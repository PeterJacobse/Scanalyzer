{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d30ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import nanonispy2 as nap\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "def get_scan(file_name, units: dict = {\"length\": \"m\", \"current\": \"A\"}, default_channel_units: dict = {\"X\": \"m\", \"Y\": \"m\", \"Z\": \"m\", \"Current\": \"A\", \"LI Demod 1 X\": \"A\", \"LI Demod 1 Y\": \"A\", \"LI Demod 2 X\": \"A\", \"LI Demod 2 Y\": \"A\"}):\n",
    "    if not os.path.exists(file_name):\n",
    "        print(f\"Error: File \\\"{file_name}\\\" does not exist.\")\n",
    "        return\n",
    "\n",
    "    root, extension = os.path.splitext(file_name)\n",
    "    if extension != \".sxm\":\n",
    "        print(\"Error: attempting to open a scan that is not an sxm file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        scan_data = nap.read.Scan(file_name) # Read the scan data. scan_data is an object whose attributes contain all the data of the scan\n",
    "        channels = np.array(list(scan_data.signals.keys())) # Read the channels\n",
    "        scan_header = scan_data.header\n",
    "        up_or_down = scan_header.get(\"scan_dir\", \"down\") # Read whether the scan was recorded in the upward or downward direction\n",
    "        pixels_uncropped = scan_header.get(\"scan_pixels\", np.array([100, 100], dtype = int)) # Read the number of pixels in the scan\n",
    "        scan_range_uncropped = scan_header.get(\"scan_range\", np.array([1E-8, 1E-8], dtype = float)) # Read the size of the scan\n",
    "        bias = round(float(scan_header.get(\"bias\", 0)), 3) # Get the bias (present in the header as a string, passed more directly as a float)\n",
    "        z_controller = scan_header.get(\"z-controller\") # Extract and convert z-controller parameters\n",
    "        feedback = bool(z_controller.get(\"on\")[0]) # Bool, true or false\n",
    "        setpoint_str = z_controller.get(\"Setpoint\")[0]\n",
    "        \n",
    "        # Extract and convert time parameters and convert to datetime object\n",
    "        rec_date = [int(element) for element in scan_data.header.get(\"rec_date\", \"00.00.1900\").split(\".\")]\n",
    "        rec_time = [int(element) for element in scan_data.header.get(\"rec_time\", \"00:00:00\").split(\":\")]\n",
    "        dt_object = datetime(rec_date[2], rec_date[1], rec_date[0], rec_time[0], rec_time[1], rec_time[2])\n",
    "        \n",
    "        # Compute the re-unitization factors\n",
    "        # Lengths\n",
    "        channel_units = default_channel_units.copy() # Initialize channel_units to the default setting\n",
    "        match units.get(\"length\", \"m\"):\n",
    "            case \"m\": L_multiplication_factor = 1\n",
    "            case \"dm\": L_multiplication_factor = 10\n",
    "            case \"cm\": L_multiplication_factor = 100\n",
    "            case \"mm\": L_multiplication_factor = 1E3\n",
    "            case \"um\": L_multiplication_factor = 1E6\n",
    "            case \"nm\": L_multiplication_factor = 1E9\n",
    "            case \"A\": L_multiplication_factor = 1E10\n",
    "            case \"pm\": L_multiplication_factor = 1E12\n",
    "            case \"fm\": L_multiplication_factor = 1E15\n",
    "            case _: L_multiplication_factor = 1\n",
    "        if L_multiplication_factor == 1: units[\"length\"] = \"m\" # Fall back to m\n",
    "    \n",
    "        # Current\n",
    "        match units.get(\"current\", \"A\"):\n",
    "            case \"A\": I_multiplication_factor = 1\n",
    "            case \"dA\": I_multiplication_factor = 10\n",
    "            case \"cA\": I_multiplication_factor = 100\n",
    "            case \"mA\": I_multiplication_factor = 1E3\n",
    "            case \"uA\": I_multiplication_factor = 1E6\n",
    "            case \"nA\": I_multiplication_factor = 1E9\n",
    "            case \"pA\": I_multiplication_factor = 1E12\n",
    "            case \"fA\": I_multiplication_factor = 1E15\n",
    "            case _: I_multiplication_factor = 1\n",
    "        if I_multiplication_factor == 1: units[\"current\"] = \"A\" # Fall back to A\n",
    "        \n",
    "        # Update the unit in channel_units (which will now be different from default_channel_units)\n",
    "        length_channels = [key for key, value in default_channel_units.items() if value == \"m\"]\n",
    "        current_channels = [key for key, value in default_channel_units.items() if value == \"A\"]\n",
    "        for channel in length_channels:\n",
    "            if channel in channel_units: channel_units[channel] = units.get(\"length\", \"m\")\n",
    "        for channel in current_channels:\n",
    "            if channel in channel_units: channel_units[channel] = units.get(\"current\", \"A\")\n",
    "        filtered_channel_units = {str(key): channel_units[key] for key in channels if key in channel_units} # Remove channels that are not present in the scan\n",
    "        channel_units = filtered_channel_units\n",
    "        \n",
    "        # Rescale the scan data by the multiplication factors determined in the reunitization        \n",
    "        for channel in channels:\n",
    "            for direction in [\"forward\", \"backward\"]:\n",
    "                if channel in length_channels: scan_data.signals[channel][direction] = np.array(scan_data.signals[channel][direction] * L_multiplication_factor, dtype = float)\n",
    "                elif channel in current_channels: scan_data.signals[channel][direction] = np.array(scan_data.signals[channel][direction] * I_multiplication_factor, dtype = float)\n",
    "        \n",
    "        # Stack the forward and backward scans for each channel in a tensor. Flip the backward scan\n",
    "        scan_tensor_uncropped = np.stack([np.stack((np.array(scan_data.signals[channel][\"forward\"], dtype = float), np.flip(np.array(scan_data.signals[channel][\"backward\"], dtype = float), axis = 1))) for channel in channels])\n",
    "        if up_or_down == \"up\": scan_tensor_uncropped = np.flip(scan_tensor_uncropped, axis = 2) # Flip the scan if it recorded in the upward direction\n",
    "        # scan_tensor: axis 0 = direction (0 for forward, 1 for backward); axis 1 = channel; axis 2 and 3 are x and y\n",
    "\n",
    "        # Determine which rows should be cropped off in case the scan was not completed\n",
    "        masked_array = np.isnan(scan_tensor_uncropped[0, 1]) # All channels have the same number of NaN values. The backward scan has more NaN values because the scan always starts in the forward direction.\n",
    "        nan_counts = np.array([sum([int(masked_array[j, i]) for i in range(len(masked_array))]) for j in range(len(masked_array[0]))])\n",
    "        good_rows = np.where(nan_counts == 0)[0]\n",
    "        scan_tensor = np.array([[scan_tensor_uncropped[channel, 0, good_rows], scan_tensor_uncropped[channel, 1, good_rows]] for channel in range(len(channels))])\n",
    "        \n",
    "        pixels = np.asarray(np.shape(scan_tensor[0, 0])) # The number of pixels is recalculated on the basis of the scans potentially being cropped\n",
    "        scan_range = np.array([scan_range_uncropped[0] * pixels[0] / pixels_uncropped[0], scan_range_uncropped[1]]) # Recalculate the size of the slow scan direction after cropping\n",
    "        \n",
    "        # Apply the re-unitization to various attributes in the header\n",
    "        scan_range = [scan_dimension * L_multiplication_factor for scan_dimension in scan_range]\n",
    "        setpoint = float(setpoint_str.split()[0]) * I_multiplication_factor\n",
    "\n",
    "        # Add new attributes to the scan object\n",
    "        setattr(scan_data, \"default_channel_units\", default_channel_units)\n",
    "        setattr(scan_data, \"channel_units\", channel_units)\n",
    "        setattr(scan_data, \"units\", units)\n",
    "        setattr(scan_data, \"bias\", bias)\n",
    "        setattr(scan_data, \"channels\", channels)\n",
    "        setattr(scan_data, \"tensor_uncropped\", scan_tensor_uncropped) # Uncropped means the size of the scan before deleting the rows that were not recorded\n",
    "        setattr(scan_data, \"pixels_uncropped\", pixels_uncropped)\n",
    "        setattr(scan_data, \"scan_range_uncropped\", scan_range_uncropped)\n",
    "        setattr(scan_data, \"tensor\", scan_tensor)\n",
    "        setattr(scan_data, \"pixels\", pixels)\n",
    "        setattr(scan_data, \"scan_range\", scan_range)\n",
    "        setattr(scan_data, \"feedback\", feedback)\n",
    "        setattr(scan_data, \"setpoint\", setpoint)\n",
    "        setattr(scan_data, \"date_time\", dt_object)\n",
    "    \n",
    "        return scan_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading sxm file: {e}\")\n",
    "\n",
    "def spec_times(folder):\n",
    "    dat_files = np.array([str(file) for file in Path(folder).glob(\"*.dat\")]) # Read all the dat files\n",
    "\n",
    "    spec_files = []\n",
    "    spec_times = []\n",
    "\n",
    "    for spec_file in dat_files:\n",
    "        try:\n",
    "            spec_object = nap.read.Spec(spec_file)\n",
    "            [spec_date, spec_time] = spec_object.header.get(\"Start time\").split()\n",
    "    \n",
    "            # Extract and convert time parameters and convert to datetime object\n",
    "            rec_date = [int(element) for element in spec_date.split(\".\")]\n",
    "            rec_time = [int(element) for element in spec_time.split(\":\")]\n",
    "            dt_object = datetime(rec_date[2], rec_date[1], rec_date[0], rec_time[0], rec_time[1], rec_time[2])\n",
    "            \n",
    "            spec_times.append(dt_object)\n",
    "            spec_files.append(spec_file)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return [np.asarray(spec_files, dtype = str), np.array(spec_times)]\n",
    "\n",
    "def get_spectrum(file_name, units: dict = {\"length\": \"m\", \"current\": \"A\"}):\n",
    "    if not os.path.exists(file_name):\n",
    "        print(f\"Error: File \\\"{file_name}\\\" does not exist.\")\n",
    "        return\n",
    "\n",
    "    root, extension = os.path.splitext(file_name)\n",
    "    if extension != \".dat\":\n",
    "        print(\"Error: attempting to open a spectroscopy file that is not a dat file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        spec_object = nap.read.Spec(file_name)\n",
    "        spec_header = spec_object.header\n",
    "        spec_coords = np.array([spec_header.get(\"X (m)\", 0), spec_header.get(\"Y (m)\", 0), spec_header.get(\"Z (m)\", 0)], dtype = float)\n",
    "        [spec_date, spec_time] = spec_header.get(\"Start time\").split()\n",
    "    \n",
    "        # Extract and convert time parameters and convert to datetime object\n",
    "        rec_date = [int(element) for element in spec_date.split(\".\")]\n",
    "        rec_time = [int(element) for element in spec_time.split(\":\")]\n",
    "        dt_object = datetime(rec_date[2], rec_date[1], rec_date[0], rec_time[0], rec_time[1], rec_time[2])\n",
    "        \n",
    "        channels = np.array(list(spec_object.signals.keys()), dtype = str)\n",
    "        spectrum_matrix = np.array(list(spec_object.signals.values()))\n",
    "        \n",
    "        # Compute the re-unitization factors\n",
    "        # Lengths\n",
    "        match units.get(\"length\", \"m\"):\n",
    "            case \"m\": L_multiplication_factor = 1\n",
    "            case \"dm\": L_multiplication_factor = 10\n",
    "            case \"cm\": L_multiplication_factor = 100\n",
    "            case \"mm\": L_multiplication_factor = 1E3\n",
    "            case \"um\": L_multiplication_factor = 1E6\n",
    "            case \"nm\": L_multiplication_factor = 1E9\n",
    "            case \"A\": L_multiplication_factor = 1E10\n",
    "            case \"pm\": L_multiplication_factor = 1E12\n",
    "            case \"fm\": L_multiplication_factor = 1E15\n",
    "            case _: L_multiplication_factor = 1\n",
    "        if L_multiplication_factor == 1: units[\"length\"] = \"m\" # Fall back to m\n",
    "    \n",
    "        # Current\n",
    "        match units.get(\"current\", \"A\"):\n",
    "            case \"A\": I_multiplication_factor = 1\n",
    "            case \"dA\": I_multiplication_factor = 10\n",
    "            case \"cA\": I_multiplication_factor = 100\n",
    "            case \"mA\": I_multiplication_factor = 1E3\n",
    "            case \"uA\": I_multiplication_factor = 1E6\n",
    "            case \"nA\": I_multiplication_factor = 1E9\n",
    "            case \"pA\": I_multiplication_factor = 1E12\n",
    "            case \"fA\": I_multiplication_factor = 1E15\n",
    "            case _: I_multiplication_factor = 1\n",
    "        if I_multiplication_factor == 1: units[\"current\"] = \"A\" # Fall back to A]\n",
    "\n",
    "        spec_coords *= L_multiplication_factor\n",
    "        for channel_index in range(len(channels)):\n",
    "            channel = channels[channel_index]\n",
    "            if channel in [\"Current (A)\", \"Current [bwd] (A)\"]:\n",
    "                spectrum_matrix[channel_index] *= I_multiplication_factor\n",
    "            elif channel in [\"X (m)\", \"Y (m)\", \"Z (m)\"]:\n",
    "                spectrum_matrix[channel_index] *= L_multiplication_factor\n",
    "\n",
    "        # Add the new attributes to the scan object\n",
    "        setattr(spec_object, \"coords\", spec_coords)\n",
    "        setattr(spec_object, \"x\", float(spec_coords[0]))\n",
    "        setattr(spec_object, \"y\", float(spec_coords[1]))\n",
    "        setattr(spec_object, \"z\", float(spec_coords[2]))\n",
    "        setattr(spec_object, \"channels\", channels)\n",
    "        setattr(spec_object, \"matrix\", spectrum_matrix)\n",
    "        setattr(spec_object, \"date_time\", dt_object)\n",
    "    \n",
    "        return spec_object\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2c21f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dir = \"C:\\\\Nanonis\\\\10182025\"\n",
    "spec_file = \"Bias-Spectroscopy00005.dat\"\n",
    "spec_object = get_spectrum(spec_dir + \"\\\\\" + spec_file, units = {\"length\": \"nm\", \"current\": \"pA\"})\n",
    "\n",
    "channels = spec_object.channels\n",
    "matrix = spec_object.matrix\n",
    "date_time = spec_object.date_time\n",
    "coords = spec_object.coords\n",
    "\n",
    "x_channel = \"Bias calc (V)\"\n",
    "y_channel = \"Current (A)\"\n",
    "\n",
    "if x_channel not in channels:\n",
    "    print(f\"The requested channel {x_channel} is not present in the selected spectrum\")\n",
    "else:\n",
    "    x_channel_index = np.where(channels == x_channel)[0][0]\n",
    "\n",
    "if y_channel not in channels:\n",
    "    print(f\"The requested channel {y_channel} is not present in the selected spectrum\")\n",
    "else:\n",
    "    y_channel_index = np.where(channels == y_channel)[0][0]\n",
    "\n",
    "x_data = matrix[x_channel_index]\n",
    "y_data = matrix[y_channel_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_object = get_scan(\"C:\\\\Data\\\\Peter\\\\WS2\\\\062325\\\\img_0049.sxm\", units = {\"length\": \"nm\", \"current\": \"A\"})\n",
    "\n",
    "print(scan_object.pixels_uncropped)\n",
    "print(scan_object.pixels)\n",
    "print(scan_object.scan_range)\n",
    "print(scan_object.scan_range_uncropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa5476bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # Save the scan folder to the config yaml file so it opens automatically on startup next time\n",
    "    with open(\"C:\\\\Scripts\\\\Scanalyzer\\\\scanalyzer\\\\config.yml\", \"w\") as file:\n",
    "        yaml.safe_dump({\"last_file\": \"C:\\\\Scripts\\\\Scanalyzer\\\\scanalyzer\\\\dummy_scan.sxm\"}, file)\n",
    "except Exception as error:\n",
    "    print(\"Failed to save the scan folder to the config.yml file.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1628be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Scripts\\Scanalyzer\\scanalyzer\\dummy_scan.sxm\n"
     ]
    }
   ],
   "source": [
    "try: # Read the last scan file from the config yaml file\n",
    "    with open(\"C:\\\\Scripts\\\\Scanalyzer\\\\scanalyzer\\\\config.yml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        last_file = config.get(\"last_file\")\n",
    "except:\n",
    "    print(\"Failed to load the last scan folder from the config.yml file.\")\n",
    "\n",
    "print(last_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:\\\\Nanonis\\\\10182025\\\\\"\n",
    "sxm_file = folder + \"unnamed0001.sxm\"\n",
    "\n",
    "scan_object = get_scan(sxm_file)\n",
    "\n",
    "\n",
    "spec_max_file_index = len(spec_files) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_files = np.array([str(file) for file in Path(folder).glob(\"*.dat\")]) # Read all the dat files\n",
    "spec_times = []\n",
    "for spec_file in spec_files:\n",
    "    spec_object = nap.read.Spec(spec_file)\n",
    "    [spec_date, spec_time] = spec_object.header.get(\"Start time\").split()\n",
    "\n",
    "    # Extract and convert time parameters and convert to datetime object\n",
    "    rec_date = [int(element) for element in spec_date.split(\".\")]\n",
    "    rec_time = [int(element) for element in spec_time.split(\":\")]\n",
    "    dt_object = datetime(rec_date[2], rec_date[1], rec_date[0], rec_time[0], rec_time[1], rec_time[2])\n",
    "    spec_times.append(dt_object)\n",
    "\n",
    "print(spec_files)\n",
    "print(spec_times)\n",
    "\n",
    "scan_time = scan_object.date_time\n",
    "[int(spec_time > scan_time) for spec_time in spec_times]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scantelligent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
